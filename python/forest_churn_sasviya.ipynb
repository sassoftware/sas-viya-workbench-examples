{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf33f760-227a-4bf3-a6d5-f240bd69bfb1",
   "metadata": {},
   "source": [
    "## ForestClassifier from SAS® Viya® on Customer Churn Data Set\n",
    "\n",
    "### About the [Churn Dataset](https://archive.ics.uci.edu/dataset/563/iranian+churn+dataset) \n",
    "\n",
    "This dataset was randomly collected from an Iranian telecom company's database over a 12-month period. It comprises 3150 rows, each representing a customer, with information across 13 columns. The dataset includes attributes such as call failures, SMS frequency, number of complaints, distinct calls, subscription length, age group, charge amount, service type, usage duration, status, usage frequency, and Customer Value.\n",
    "\n",
    "All attributes, except for the churn attribute, consist of aggregated data from the first 9 months. The churn labels indicate the customers' status at the end of the 12-month period. The three-month gap is designated for planning purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5168d4-a563-4f81-852c-d26d326da665",
   "metadata": {},
   "source": [
    "### Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3846a694-1051-4bb8-aded-9c17c4208acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, auc, roc_curve, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sasviya.ml.tree import ForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8782cf6-e89c-492f-98db-3f8e342375ff",
   "metadata": {},
   "source": [
    "### Import customer churn data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfebd2c7-8190-457d-8d2c-bdb205ec2453",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace=f'{os.path.abspath(\"\")}/../data/'\n",
    "churn_df=pd.read_csv(workspace+'churn.csv')\n",
    "churn_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59966291-fa22-4b0d-8e2c-ac1ddca6c4e7",
   "metadata": {},
   "source": [
    "### Split the data \n",
    "\n",
    "When training any supervised learning model, it is important to split the data into training and test data. The training data is used to fit the model. The algorithm uses the training data to learn the relationship between the features and the target. The test data is used to evaluate the performance of the model.\n",
    "\n",
    "The code below splits the data into separate variables for the features and target, then splits into 80% training and 20% test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894cea13-3eac-46f4-95af-79aac8d50bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = churn_df.drop('Churn', axis=1)\n",
    "y = churn_df['Churn']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y, stratify=y, test_size = 0.2, random_state = 10)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5475675f-957a-4b26-a6a7-23ec98aa068e",
   "metadata": {},
   "source": [
    "### Fit and evaluate the forest model\n",
    "\n",
    "First, we instantiate the Forest model with default parameters. Subsequently, we train the model using our training data by providing both the features and the target variable, enabling the model to learn.\n",
    "\n",
    "For details about using the `ForestClassifier` class in the `sasviya` package, see the [ForestClassifier documentation](https://documentation.sas.com/?cdcId=workbenchcdc&cdcVersion=default&docsetId=explore&docsetTarget=p04zhxjh60eutqn1t40f0104gw42.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8fcaa7-151b-4736-a445-0d4184464d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ForestClassifier(n_estimators=100, \n",
    "                      max_depth=5,\n",
    "                      min_samples_leaf=1,\n",
    "                      max_features=None,\n",
    "                      criterion='gini',\n",
    "                      random_state=0)\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51292574-c876-4cb2-ae50-86105b3332ae",
   "metadata": {},
   "source": [
    "At this stage, we have a trained Forest model; next, we need to determine if it is making accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcba62ef-9fd4-4d44-bde8-de2439c0b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326f461b-d9ec-4671-bba2-944d54809891",
   "metadata": {},
   "source": [
    "The simplest way to evaluate this model is by using accuracy. We compare the predictions with the actual values in the test set and tally the number of correct predictions made by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d89a9ad-06dc-4b3a-8ac7-7cade436a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", '{:.4f}'.format(accuracy))\n",
    "print(\"Precision:\", '{:.4f}'.format(precision))\n",
    "print(\"Recall:\", '{:.4f}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24480924-26f8-4e9b-ac73-e4ddb45b2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = rf.predict_proba(X_test).to_numpy()\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Resampled Random Forest (area = %0.4f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53146074-bb8f-419e-b6a8-cd19b0575309",
   "metadata": {},
   "source": [
    "This is a commendable score! Nevertheless, we might achieve even better results by optimizing our hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be1a812-b37c-4118-aee2-e1560dad6f18",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "The code snippet below utilizes Scikit-Learn’s **RandomizedSearchCV**, which conducts a random search for parameters within specified ranges for each hyperparameter. We define the hyperparameters to be used and their respective ranges in the param_dist dictionary. In this scenario, we are utilizing:\n",
    "* **n_estimators**: the number of decision trees in the forest. Increasing this hyperparameter typically enhances the model's performance, albeit at the cost of increased computational resources for training and prediction.\n",
    "* **max_depth**: the maximum depth of each decision tree in the forest. Setting a higher value for max_depth can result in overfitting, while setting it too low may lead to underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29062816-599b-47ca-b402-7a1030ae63a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'n_estimators': randint(100,300),\n",
    "              'max_depth': randint(1,20)}\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf = ForestClassifier()\n",
    "\n",
    "# Use random search to find the best hyperparameters\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions = param_dist, \n",
    "                                 n_iter=5, \n",
    "                                 cv=5)\n",
    "\n",
    "# Fit the random search object to the data\n",
    "rand_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983491bd-e113-4f55-b9a1-dfda8a07d41a",
   "metadata": {},
   "source": [
    "RandomizedSearchCV will train multiple models (determined by n_iter_) and save each one as variables. The code snippet below creates a variable for the best model and displays the hyperparameters. In this instance, we have not specified a scoring metric for the function, so it defaults to accuracy. Additionally, this function employs cross-validation, where the data is divided into five equally sized groups, using four for training and one for testing. It iterates through each group, providing an accuracy score that is averaged to determine the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ed6d98-b75a-41d0-b5c6-121649bab319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable for the best modelmetrics\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters:',  rand_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe3d38c-3c04-4d68-be78-a43643d7a181",
   "metadata": {},
   "source": [
    "### More Evaluation Metrics\n",
    "\n",
    "Now, let's examine the confusion matrix. This matrix illustrates the model's predictions compared to the actual correct predictions. It helps us grasp the balance between false positives (top right) and false negatives (bottom left). We can visualize the confusion matrix using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313c7a31-36bb-4465-b52e-97be40d754ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions with the best model\n",
    "y_pred = best_rf.predict(X_test).astype(type(y_test[0]))\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a05e55-0efc-4cac-b272-1719c5a2b4b6",
   "metadata": {},
   "source": [
    "It is advisable to assess the best model using accuracy, precision, and recall. Please note that your results may vary due to randomization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b048a069-5c63-4c4b-9d6c-095d28514ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_rf.predict(X_test).astype(type(y_test[0]))\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", '{:.4f}'.format(accuracy))\n",
    "print(\"Precision:\", '{:.4f}'.format(precision))\n",
    "print(\"Recall:\", '{:.4f}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37999857-3c7e-41cf-8104-f025d798db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = best_rf.predict_proba(X_test).to_numpy()\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Resampled Random Forest RandomizedSearchCV (area = %0.4f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf6acf2-dcc8-4f57-88f5-9df976ddcd80",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f78f247-78e7-4676-9fcf-e7c2395e955d",
   "metadata": {},
   "source": [
    "The code below visualizes the importance of each feature by utilizing the model's internal score to determine the optimal way to split the data within each decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299515dd-c7d3-47ce-a9d2-c19af09457cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a series that includes feature importances from the model and feature names from the training data\n",
    "feature_importances = best_rf.feature_importances_.set_index('Variable')['Importance']\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))  # Adjust the width (10) and height (6) as desired\n",
    "\n",
    "# Plot a simple bar chart\n",
    "feature_importances.plot.bar();\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Feature Importance');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
